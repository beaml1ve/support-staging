# Session-Specific Rules
# This file contains rules active during this support session
# Original platform rules copied and can be modified for this session context
# Session ID: 2025-09-20_08-12-41_organization-statistics-excel

# Support Staging Monorepo Rules

## Monorepo Structure

This is an npm workspace-based monorepo for support staging environments. Each platform has its own workspace with specific configurations and tools.

## Core Constraints and Principles

### 1. **Rules Protection System**
- **CRITICAL**: Root and platform .cursorrules files are protected by default
- **Modification Requires**: Explicit unprotection via `npm run unprotect-rules <target>`
- **Protection Commands**:
  - `npm run protect-rules root` - Protect root rules
  - `npm run protect-rules staging` - Protect platform rules
  - `npm run unprotect-rules root` - Allow root rules modification
  - `npm run unprotect-rules staging` - Allow platform rules modification
  - `npm run rules-status` - Show protection status
- **Auto-Protection**: Rules should be re-protected after modifications

### 2. **Context Switching System**
- **MANDATORY**: Use context switching for platform-specific work
- **Commands**:
  - `source scripts/set-context.sh <platform>` - Set context, cd to platform, npm install
  - `source scripts/set-context.sh <platform> --skip-install` - Set context without npm install
  - `source scripts/set-context.sh` (no args) - Restore monorepo root configuration
- **Behavior**: Context switching automatically handles configuration symlinks and directory changes
- **Aliases**: Load with `source scripts/context-aliases.sh` for short commands

### 3. **Workspace Isolation**
- **Platform Independence**: Each platform workspace is completely self-contained
- **Configuration Isolation**: Platform-specific .cursorrules and MCP settings
- **Dependency Management**: Platform-specific package.json and dependencies
- **Session Isolation**: Each session within a platform has its own rules and context

## Workspace Organization
```
support-staging/                 # Root monorepo
├── package.json                # Root package.json with workspaces config
├── .cursor/                    # Root MCP settings
│   └── mcp_settings.json      # Monorepo-wide MCP configuration
├── .cursorrules               # This file - monorepo rules
├── scripts/                   # Monorepo management scripts
│   ├── set-context.sh         # Context switching (with directory change)
│   ├── unset-context.sh       # Legacy unset script
│   ├── context-aliases.sh     # Convenient aliases
│   └── protect-rules.js       # Rules protection system
└── platforms/                 # Platform-specific workspaces
    └── staging/               # Staging platform workspace
        ├── package.json       # Workspace-specific package.json
        ├── .cursor/           # Platform-specific MCP settings
        │   └── mcp_settings.json
        ├── .cursorrules       # Platform-specific rules
        ├── scripts/           # Platform session management
        │   ├── open-session.js
        │   └── close-session.js
        ├── session-logs/      # Support session documentation
        └── pm2-restart/       # PM2 management scripts
```

## Platform Configuration

### **Staging Environment (beamdevlive ecosystem)**

#### **Environment-Specific Configuration**
- **Ecosystem Name**: `beamdevlive`
- **Redis BDS**: `10.128.0.21:6379` (main BDS instance)
- **Redis BDS Alt**: `10.128.0.21:6380` (alternative port)
- **MQTT Broker**: `localhost:1883`
- **MQTT Credentials**: 
  - Username: `explorer`
  - Password: `beamL1ve`

#### **Platform Services**
- **Apache2**: Web server and reverse proxy
- **PostgreSQL**: Database clusters (versions 9.6 and 14)
- **Redis HA**: High availability Redis instances
- **Mosquitto**: MQTT message broker
- **Tile38**: Geospatial database (10.128.0.11:9851)

#### **Microservices**
- **Count**: 260+ Node.js services managed by PM2
- **Management**: PM2 process manager with ecosystem configuration
- **Logs**: Accessible via `pm2m logs <service-name>` with time filtering
- **Monitoring**: Health checks and status monitoring via PM2

### **Investigation Commands and Tools**

#### **System Health Commands**
```bash
# OS Health Check
uptime && free -h && df -h / && iostat 1 1

# Platform Services Status
systemctl status apache2 postgresql redis mosquitto tile38 --no-pager

# Redis BDS Connection Test
redis-cli -h 10.128.0.21 -p 6379 ping
```

#### **Microservice Investigation**
```bash
# PM2 Service Status
pm2 list | grep <service-name>
pm2 show <pm2-id>

# Log Analysis with Time Filtering
../../pm2/scripts/pm2m logs <service-name> --from now-12h --to now
../../pm2/scripts/pm2m logs <service-name> --from now-1d --to now | grep -E "error|Error|failed|Failed"
```

#### **Workflow Analysis Commands**
```bash
# Find Workflow ID from Logs
../../pm2/scripts/pm2m logs work-admin-dev --from now-12h --to now | grep -E "workflow.*created|LOG.*registerUserByAdmin"

# Retrieve Complete Workflow (Source + Runtime)
redis-cli -h 10.128.0.21 -p 6379 JSON.GET "beamdevlive:workflow:<workflowId>:work-admin"

# Filter Workflow State Transitions
../../pm2/scripts/pm2m logs work-admin-dev --from now-12h --to now | grep "LOG.*registerUserByAdmin" | head -20
```

#### **MQTT Testing Commands**
```bash
# Generate UUID for Request
REQUEST_ID=$(uuidgen)

# Subscribe to Reply Topic
mosquitto_sub -h localhost -p 1883 -u explorer -P beamL1ve -t "beamdevlive/service/work-admin/service/<org-service>/register/reply" -C 1 &

# Publish Request
mosquitto_pub -h localhost -p 1883 -u explorer -P beamL1ve -t "beamdevlive/service/work-admin/service/<org-service>/register" -m '{"id":"'$REQUEST_ID'","pattern":"beamdevlive/service/work-admin/service/<org-service>/register","data":{...}}'
```

### **Platform-Specific Investigation Lessons**

#### **Admin Registration Troubleshooting (beamdevlive ecosystem)**
- **force1FR Flag Check**: Always verify `force1FR: true` for admin-initiated registrations
- **TypeId 2 Issues**: 2FA registrations require proper force1FR handling
- **Common Error Pattern**: `"user with ids cannot be created"` often indicates force1FR: false issue
- **Security Working**: Services rejecting unverified 2FA are functioning correctly
- **Investigation Priority**: Check authentication parameters before assuming service bugs

## Workspace Commands

### Root Level Commands:
```bash
# Install all workspace dependencies
npm run install:all

# Run commands across all workspaces
npm run build --workspaces
npm run test --workspaces
npm run lint --workspaces

# Clean all workspaces
npm run clean --workspaces

# Rules protection
npm run protect-rules <target>     # Protect rules (root, staging, all)
npm run unprotect-rules <target>   # Unprotect rules
npm run rules-status               # Show protection status
```

### Platform-Specific Work:
```bash
# Set context and navigate to specific platform (RECOMMENDED)
source scripts/set-context.sh staging

# Or load aliases first, then use short commands
source scripts/context-aliases.sh
set-context staging

# Return to monorepo root
set-context
```

## Context Switching System

### Quick Start:
```bash
# Load context aliases (optional, for convenience)
source scripts/context-aliases.sh

# Set context (switches config + changes directory + npm install)
set-context staging

# Work in platform-specific environment with session management
npm run open-session "performance-optimization"

# Work with platform-specific .cursorrules and MCP settings...
# Document work in session-notes.md...

# Close session and generate documentation
npm run close-session

# Return to monorepo root
set-context
```

### Available Commands:
- **`source scripts/set-context.sh <platform>`**: Set context and cd to platform
- **`source scripts/set-context.sh <platform> --skip-install`**: Set context without npm install
- **`source scripts/set-context.sh`**: Restore monorepo root configuration
- **`npm run context-status`**: Check current active context
- **`source scripts/context-aliases.sh`**: Load convenient aliases

### How It Works:
1. **Initialize**: Always restores root configs first (removes any existing symlinks)
2. **Backup**: Original monorepo configs are backed up (only once)
3. **Symlink**: Platform-specific configs are symlinked to root
4. **Directory**: Working directory changes to platform folder
5. **Install**: npm install runs in platform workspace (unless --skip-install)
6. **Restore**: Unset restores original configs and returns to root


## Development Workflow

### Working with Platforms:
1. **Set Context**: Use `source scripts/set-context.sh <platform>` to activate platform-specific configuration and navigate to workspace
2. **Open Session**: Use `npm run open-session <session-name>` for all support work
3. **Platform-Specific Work**: Use platform and session-specific MCP settings and rules automatically
4. **Document Work**: All actions documented in session notes and auto-generated summaries
5. **Close Session**: Use `npm run close-session` to generate comprehensive documentation
6. **Return to Root**: Use `source scripts/set-context.sh` (no args) to restore monorepo configuration
7. **Commit Changes**: Always commit from the root level to maintain monorepo integrity

### Git Workflow:
```bash
# Always commit from root level
cd ~/support-staging
git add .
git commit -m "feat(platform): description of changes"
git push origin main
```

## Best Practices

1. **Platform Isolation**: Each platform workspace is self-contained
2. **Context Switching**: Always use context system for platform-specific work
3. **Session Management**: Use session system for all support work
4. **Rules Protection**: Protect rules when not actively modifying them
5. **Shared Dependencies**: Common dependencies managed at root level
6. **Documentation**: Platform-specific docs stay in platform workspace
7. **MCP Settings**: Platform-specific Redis/service connections in platform MCP settings
8. **Support Sessions**: Always use session management system for structured documentation

## Troubleshooting

### Workspace Issues:
```bash
# Reinstall all workspace dependencies
npm run clean --workspaces
npm run install:all

# Check workspace configuration
npm ls --workspaces

# Verify platform structure
ls -la platforms/*/
```

### Context Switching Issues:
```bash
# Check current context
npm run context-status

# Reset to root configuration
source scripts/set-context.sh

# Check rules protection status
npm run rules-status
```

### Session Management Issues:
```bash
# Check active session (in platform workspace)
npm run session-status

# List all sessions
npm run list-sessions

# Force close session if needed
rm .active-session
```

## Security and Safety

- **Rules Protection**: Prevents accidental modification of critical .cursorrules files
- **Context Isolation**: Platform configurations don't interfere with each other
- **Session Isolation**: Each support session has its own rules and documentation context
- **Backup System**: Original configurations are always preserved and restorable
- **Structured Documentation**: All support work is automatically documented with timestamps and metadata

## Firebase FCM Token Management

### **Firebase Configuration and Credentials**

#### **Environment Configuration (beamdevlive ecosystem)**
- **Project ID**: `beam-live-passenger`
- **Client Email**: `firebase-adminsdk-fffpq@beam-live-passenger.iam.gserviceaccount.com`
- **Private Key Source**: `/var/www/beamdevlive/notification-service/.env`
- **Database URL**: `https://beamlive-ff2d7.firebaseio.com`

#### **FCM Token Storage in BDS**
- **Correct Index**: `beamdevlive:device:token`
- **Search Tag**: `@fcmTokenUserId:{userId}`
- **Token Path**: `$.nonpersistent.static.live.fcmToken.token`
- **Wrong Index**: `beamdevlive:deviceUdidIndex` (commonly misused by services)

#### **Firebase Credentials Extraction Script**
```bash
# Extract and format Firebase private key from notification-service
cat > extract_firebase_key.sh << 'EOF'
#!/bin/bash
echo "=== Extracting Firebase Private Key ==="
key_line=$(grep "FIREBASE_ADMIN_SERVICE_ACCOUNT_PRIVATE_KEY" /var/www/beamdevlive/notification-service/.env)
private_key_raw=$(echo "$key_line" | cut -d'=' -f2-)
echo "$private_key_raw" | \
  sed 's/-----BEGINPRIVATEKEY-----/-----BEGIN PRIVATE KEY-----/g' | \
  sed 's/-----ENDPRIVATEKEY-----/-----END PRIVATE KEY-----/g' | \
  sed 's/\\n/\n/g' > formatted_key.txt
echo "✅ Key saved to: formatted_key.txt"
EOF
chmod +x extract_firebase_key.sh
```

### **FCM Token Testing and Validation Tools**

#### **Complete Token Validation Script Template**
```javascript
const admin = require('firebase-admin');
const fs = require('fs');

async function validateFCMTokens() {
  try {
    // Load properly formatted Firebase credentials
    const privateKey = fs.readFileSync('formatted_key.txt', 'utf8');
    const firebaseConfig = {
      projectId: "beam-live-passenger",
      clientEmail: "firebase-adminsdk-fffpq@beam-live-passenger.iam.gserviceaccount.com",
      privateKey: privateKey
    };

    // Initialize Firebase Admin SDK
    if (admin.apps.length > 0) {
      await Promise.all(admin.apps.map(app => app.delete()));
    }
    admin.initializeApp({
      credential: admin.credential.cert(firebaseConfig)
    });

    // Load FCM tokens from BDS or file
    const tokens = [/* token array */];
    
    // Batch validation with error handling
    const batchSize = 10;
    let validTokens = 0;
    let invalidTokens = 0;
    const errorBreakdown = {};
    
    for (let i = 0; i < tokens.length; i += batchSize) {
      const batch = tokens.slice(i, i + batchSize);
      
      for (const token of batch) {
        try {
          await admin.messaging().send({
            token: token,
            notification: { title: 'Test', body: 'Validation' },
            data: { test: 'validation' }
          }, true); // dryRun = true
          
          validTokens++;
        } catch (error) {
          invalidTokens++;
          const errorCode = error.code || 'unknown';
          errorBreakdown[errorCode] = (errorBreakdown[errorCode] || 0) + 1;
        }
      }
    }
    
    // Save results
    const results = {
      validation_timestamp: new Date().toISOString(),
      total_tokens: tokens.length,
      valid_tokens: validTokens,
      invalid_tokens: invalidTokens,
      validation_rate: ((validTokens/tokens.length)*100).toFixed(1) + '%',
      error_breakdown: errorBreakdown
    };
    
    fs.writeFileSync('fcm-validation-results.json', JSON.stringify(results, null, 2));
    console.log(`✅ Validation complete: ${validTokens}/${tokens.length} valid (${results.validation_rate})`);
    
  } catch (error) {
    console.error('❌ Validation failed:', error.message);
  }
}

validateFCMTokens();
```

#### **FCM Token Collection from BDS Script Template**
```bash
# Collect FCM tokens for specific users from correct BDS index
collect_user_fcm_tokens() {
  local user_ids=("$@")
  
  echo "{"
  echo "  \"collection_timestamp\": \"$(date -Iseconds)\","
  echo "  \"user_tokens\": ["
  
  local first=true
  for userId in "${user_ids[@]}"; do
    if [ "$first" = false ]; then echo ","; fi
    first=false
    
    echo -n "    {\"user_id\": \"$userId\", \"fcm_tokens\": ["
    
    # Query correct BDS index for FCM tokens
    device_objects=$(redis-cli -h localhost -p 6379 FT.SEARCH "beamdevlive:device:token" "@fcmTokenUserId:{$userId}" LIMIT 0 100 2>/dev/null | grep "beamdevlive:device:")
    
    local token_first=true
    if [ -n "$device_objects" ]; then
      while IFS= read -r device_key; do
        if [ -n "$device_key" ]; then
          token=$(redis-cli -h localhost -p 6379 JSON.GET "$device_key" "$.nonpersistent.static.live.fcmToken.token" 2>/dev/null)
          clean_token=$(echo "$token" | sed 's/^\[\"\(.*\)\"\]$/\1/' | sed 's/^"\(.*\)"$/\1/')
          
          if [ -n "$clean_token" ] && [ "$clean_token" != "null" ] && [ "$clean_token" != "[]" ]; then
            if [ "$token_first" = false ]; then echo -n ", "; fi
            token_first=false
            echo -n "\"$clean_token\""
          fi
        fi
      done <<< "$device_objects"
    fi
    
    echo -n "]}"
  done
  
  echo ""
  echo "  ]"
  echo "}"
}

# Usage: collect_user_fcm_tokens "102563" "111557" "9"
```

#### **Firebase Authentication Debug Script Template**
```javascript
// Debug Firebase configuration and test authentication
async function debugFirebaseAuth() {
  try {
    // Extract Firebase config from notification-service .env
    const envContent = fs.readFileSync('/var/www/beamdevlive/notification-service/.env', 'utf8');
    
    const projectIdMatch = envContent.match(/FIREBASE_ADMIN_SERVICE_ACCOUNT_PROJECT_ID=(.+)/);
    const clientEmailMatch = envContent.match(/FIREBASE_ADMIN_SERVICE_ACCOUNT_CLIENT_EMAIL=(.+)/);
    
    const projectId = projectIdMatch ? projectIdMatch[1].trim() : 'beam-live-passenger';
    const clientEmail = clientEmailMatch ? clientEmailMatch[1].trim() : 'firebase-adminsdk-fffpq@beam-live-passenger.iam.gserviceaccount.com';
    
    console.log('Firebase Config:');
    console.log('Project ID:', projectId);
    console.log('Client Email:', clientEmail);
    
    // Test authentication with extracted config
    const privateKey = fs.readFileSync('formatted_key.txt', 'utf8');
    const config = { projectId, clientEmail, privateKey };
    
    admin.initializeApp({ credential: admin.credential.cert(config) });
    console.log('✅ Firebase authentication successful');
    
    // Test messaging service
    const messaging = admin.messaging();
    console.log('✅ Messaging service accessible');
    
  } catch (error) {
    console.error('❌ Authentication failed:', error.message);
  }
}
```

### **FCM Token Management Best Practices**

#### **Token Validation Workflow**
1. **Extract Credentials**: Use `extract_firebase_key.sh` to get properly formatted private key
2. **Collect Tokens**: Query `beamdevlive:device:token` index with `@fcmTokenUserId` tag
3. **Validate Tokens**: Use Firebase Admin SDK with dry run to test token validity
4. **Error Analysis**: Categorize errors (`registration-token-not-registered`, `invalid-registration-token`)
5. **Cleanup**: Remove invalid tokens from BDS to improve performance

#### **Common FCM Token Issues**
- **Wrong Index**: Services querying `beamdevlive:deviceUdidIndex` instead of `beamdevlive:device:token`
- **Invalid Tokens**: 70%+ of stored tokens may be unregistered with FCM
- **Missing Tokens**: Only ~35% of users typically have FCM tokens available
- **Authentication**: Wrong Firebase project configuration (beam-dev-live vs beam-live-passenger)

#### **Performance Optimization**
- **Token Caching**: Cache valid tokens to reduce Firebase API calls
- **Batch Validation**: Process tokens in batches of 10-100 to avoid rate limits
- **Regular Cleanup**: Remove invalid tokens weekly to reduce BDS storage
- **Monitoring**: Track token validity rates and delivery success metrics

## Organization Hierarchy and Database Structure

### **Organization Hierarchy (beamdevlive ecosystem)**

#### **Organization Types and Structure**
- **Total Organizations**: 222 active organizations
- **Organization Pattern**: Each organization has a unique `serviceId` (e.g., `org-mhany01`, `cudb-live`, `beam`)
- **Organization Status**: All organizations have `objectStatus: "active"` and `info.type: "service:cudb"`
- **Database Pattern**: Each organization has its own PostgreSQL database with `-dev` suffix

#### **Key Organization Categories**
1. **Root Organizations**:
   - `cudb-root`: Main root organization (14,949 active users, 1,163 registered)
   - `cudb-live`: Public/live organization (13,132 active users, 600 registered, 5,321 non-beamer)

2. **MHA Organizations** (Mental Health America):
   - Pattern: `org-mha*` (e.g., `org-mhany01`, `org-mhaca01`, `org-mhasc01`)
   - Count: 100+ MHA organizations across different states
   - Most have 0 registered users (pending registration)

3. **Transportation Organizations**:
   - `org-notaxi`: 83 registered users
   - `org-quincy`: 82 registered users  
   - `org-saferide-africa`: 77 registered users
   - `org-lataxi`, `org-serbia-taxi`: Taxi services

4. **Educational Organizations**:
   - `org-ksa-school`, `org-sa-school`: School districts
   - `org-beaconhouse`, `org-alforfan-school`: Educational institutions

5. **Healthcare Organizations**:
   - `mhadutchess`: 153 registered users
   - Various `org-mha*` mental health organizations

#### **User Distribution Patterns**
- **Hierarchical Storage**: Users primarily stored in `cudb-root` and `cudb-live`
- **Organization Association**: Each user has `serviceId` property indicating their organization
- **Registration Status**: 
  - `registered`: Users with `register.status: "registered"`
  - `pending`: Users with `register.status: "pending"`
  - `non-beamer`: Users with `persistent.static.nonBeamer` property and `register.status: "pending"`

### **PostgreSQL Database Structure**

#### **Database Connection Details**
- **Host**: localhost:5432
- **User**: beam
- **Password**: beamL1ve
- **PostgreSQL Version**: 14.5 (Ubuntu 14.5-1.pgdg18.04+1)
- **Total Databases**: 247 databases

#### **Database Naming Convention**
- **Pattern**: `{organization-name}-dev`
- **Examples**:
  - `cudb-root-dev` - Root organization database
  - `cudb-live-dev` - Live organization database
  - `org-mhany01-dev` - MHA New York organization database
  - `beam-dev` - Beam organization database
  - `alstom-dev` - Alstom organization database

#### **Database Categories**
1. **Organization Databases** (`*-dev`): Individual organization data
2. **System Databases**: `postgres`, `template0`, `template1`
3. **Storage Databases**: 
   - `bds-storage-dev` - BDS storage
   - `beamIdStorage-dev` - Beam ID storage
   - `iot-storage-dev` - IoT data storage
4. **Central Databases**: `central-dev`, `central`

#### **Database Access Control**
- **Owner**: Most databases owned by `postgres` user
- **Beam User Access**: The `beam` user has access to many organization databases
- **Encoding**: All databases use UTF8 encoding
- **Collation**: C.UTF-8

#### **PostgreSQL Connection Commands**
```bash
# Test connection
PGPASSWORD=beamL1ve psql -h localhost -p 5432 -U beam -d postgres -c "SELECT version();"

# List all databases
PGPASSWORD=beamL1ve psql -h localhost -p 5432 -U beam -d postgres -c "\l"

# Connect to specific organization database
PGPASSWORD=beamL1ve psql -h localhost -p 5432 -U beam -d cudb-live-dev

# Get database size
PGPASSWORD=beamL1ve psql -h localhost -p 5432 -U beam -d postgres -c "SELECT pg_size_pretty(pg_database_size('cudb-live-dev')) as database_size;"
```

#### **Database Schema Patterns**
- Each organization database contains organization-specific tables and data
- Schema isolation ensures data separation between organizations
- Common patterns likely include user tables, configuration tables, and organization-specific data

### **Organization Statistics Summary**
- **Total Active Users**: 31,446 users across all organizations
- **Total Registered Users**: 2,765 users (8.8% registration rate)
- **Total Non-Beamer Users**: 5,321 users (16.9% of total)
- **Organizations with Users**: 79 organizations have registered users
- **Organizations without Users**: 143 organizations have 0 registered users

### **Parent Organization Hierarchy Rules**

#### **PostgreSQL Hierarchy Tables**
- **cudb-relation Table**: Contains organization hierarchy relationships
  - `groupId`: Group identifier for hierarchy grouping
  - `cudbId`: Foreign key reference to cudb table
  - `deletedAt`: Soft delete timestamp (NULL for active relationships)
- **cudb Table**: Contains organization details
  - `id`: Primary key
  - `serviceId`: Organization service identifier (matches Redis BDS serviceId)
  - `deletedAt`: Soft delete timestamp (NULL for active organizations)

#### **Parent Organization Finding Logic**
1. **Root Parent Identification**: 
   - Find parent organization by selecting `groupId = 1` in cudb-relation table
   - This identifies the root parent organization (typically `cudb-root`)

2. **Hierarchy Query Pattern**:
   ```sql
   -- Find parent organization for a given child organization
   WITH parent_mapping AS (
       SELECT DISTINCT
           c1."serviceId" as child_service_id,
           c2."serviceId" as parent_service_id
       FROM "cudb-relation" cr1
       JOIN cudb c1 ON cr1."cudbId" = c1.id
       JOIN "cudb-relation" cr2 ON cr1."groupId" = cr2."groupId" AND cr2."groupId" = 1
       JOIN cudb c2 ON cr2."cudbId" = c2.id
       WHERE cr1."groupId" IS NOT NULL 
       AND cr1."groupId" != 1
       AND c1."serviceId" != c2."serviceId"
       AND cr1."deletedAt" IS NULL
       AND cr2."deletedAt" IS NULL
       AND c1."deletedAt" IS NULL
       AND c2."deletedAt" IS NULL
   )
   SELECT child_service_id, parent_service_id FROM parent_mapping;
   ```

3. **Database Connection for Hierarchy Queries**:
   ```bash
   # Connect to PostgreSQL for hierarchy queries
   PGPASSWORD=beamL1ve psql -h localhost -p 5432 -U beam -d postgres
   
   # Test hierarchy query
   PGPASSWORD=beamL1ve psql -h localhost -p 5432 -U beam -d postgres -c "
   SELECT cr.\"groupId\", cr.\"cudbId\", c.\"serviceId\" 
   FROM \"cudb-relation\" cr 
   JOIN cudb c ON cr.\"cudbId\" = c.id 
   WHERE cr.\"groupId\" = 1;"
   ```

#### **Parent Organization Integration Rules**
- **Excel Column**: Add `ParentServiceId` column to organization statistics
- **Data Source**: Query PostgreSQL cudb-relation and cudb tables
- **Relationship Logic**: 
  - Organizations with `groupId = 1` are root parents
  - Organizations in same group but not `groupId = 1` are children
  - Parent is the organization with `groupId = 1` in the same group
- **Null Handling**: Organizations without parent relationships show empty ParentServiceId
- **Validation**: Ensure parent-child relationships are logical (parent != child)

#### **Hierarchy Analysis Commands**
```bash
# Find all group relationships
PGPASSWORD=beamL1ve psql -h localhost -p 5432 -U beam -d postgres -c "
SELECT DISTINCT \"groupId\" FROM \"cudb-relation\" 
WHERE \"groupId\" IS NOT NULL ORDER BY \"groupId\";"

# Get sample hierarchy data
PGPASSWORD=beamL1ve psql -h localhost -p 5432 -U beam -d postgres -c "
SELECT cr.\"groupId\", cr.\"cudbId\", c.\"serviceId\" 
FROM \"cudb-relation\" cr 
JOIN cudb c ON cr.\"cudbId\" = c.id 
WHERE cr.\"groupId\" IS NOT NULL 
ORDER BY cr.\"groupId\", cr.\"cudbId\" 
LIMIT 20;"

# Count organizations per group
PGPASSWORD=beamL1ve psql -h localhost -p 5432 -U beam -d postgres -c "
SELECT cr.\"groupId\", COUNT(*) as org_count
FROM \"cudb-relation\" cr 
WHERE cr.\"deletedAt\" IS NULL
GROUP BY cr.\"groupId\" 
ORDER BY cr.\"groupId\";"
```

#### **Parent Organization Best Practices**
- **Always check deletedAt**: Filter out soft-deleted relationships
- **Validate relationships**: Ensure parent-child relationships make logical sense
- **Handle missing parents**: Some organizations may not have parent relationships
- **Group analysis**: Understand the group structure before determining parent-child relationships
- **Performance**: Use proper indexing on groupId and cudbId for large datasets

## Project Context

This monorepo supports multiple staging environments with platform-specific infrastructure, services, and troubleshooting procedures. Each platform workspace contains complete documentation and tools for that specific environment.

The system enforces structured workflows through context switching, session management, and rules protection to ensure consistent documentation and prevent accidental modifications to critical configuration files.
