# Support Staging Monorepo Rules

## Monorepo Structure

This is an npm workspace-based monorepo for support staging environments. Each platform has its own workspace with specific configurations and tools.

## Core Constraints and Principles

### 1. **Rules Protection System**
- **CRITICAL**: Root and platform .cursorrules files are protected by default
- **Modification Requires**: Explicit unprotection via `npm run unprotect-rules <target>`
- **Protection Commands**:
  - `npm run protect-rules root` - Protect root rules
  - `npm run protect-rules staging` - Protect platform rules
  - `npm run unprotect-rules root` - Allow root rules modification
  - `npm run unprotect-rules staging` - Allow platform rules modification
  - `npm run rules-status` - Show protection status
- **Auto-Protection**: Rules should be re-protected after modifications

### 2. **Context Switching System**
- **MANDATORY**: Use context switching for platform-specific work
- **Commands**:
  - `source scripts/set-context.sh <platform>` - Set context, cd to platform, npm install
  - `source scripts/set-context.sh <platform> --skip-install` - Set context without npm install
  - `source scripts/set-context.sh` (no args) - Restore monorepo root configuration
- **Behavior**: Context switching automatically handles configuration symlinks and directory changes
- **Aliases**: Load with `source scripts/context-aliases.sh` for short commands

### 3. **Workspace Isolation**
- **Platform Independence**: Each platform workspace is completely self-contained
- **Configuration Isolation**: Platform-specific .cursorrules and MCP settings
- **Dependency Management**: Platform-specific package.json and dependencies
- **Session Isolation**: Each session within a platform has its own rules and context

## Workspace Organization
```
support-staging/                 # Root monorepo
├── package.json                # Root package.json with workspaces config
├── .cursor/                    # Root MCP settings
│   └── mcp_settings.json      # Monorepo-wide MCP configuration
├── .cursorrules               # This file - monorepo rules
├── scripts/                   # Monorepo management scripts
│   ├── set-context.sh         # Context switching (with directory change)
│   ├── unset-context.sh       # Legacy unset script
│   ├── context-aliases.sh     # Convenient aliases
│   └── protect-rules.js       # Rules protection system
└── platforms/                 # Platform-specific workspaces
    └── staging/               # Staging platform workspace
        ├── package.json       # Workspace-specific package.json
        ├── .cursor/           # Platform-specific MCP settings
        │   └── mcp_settings.json
        ├── .cursorrules       # Platform-specific rules
        ├── scripts/           # Platform session management
        │   ├── open-session.js
        │   └── close-session.js
        ├── session-logs/      # Support session documentation
        └── pm2-restart/       # PM2 management scripts
```

## Platform Configuration

### **Staging Environment (beamdevlive ecosystem)**

#### **Environment-Specific Configuration**
- **Ecosystem Name**: `beamdevlive`
- **Redis BDS**: `10.128.0.21:6379` (main BDS instance)
- **Redis BDS Alt**: `10.128.0.21:6380` (alternative port)
- **MQTT Broker**: `localhost:1883`
- **MQTT Credentials**: 
  - Username: `explorer`
  - Password: `beamL1ve`

#### **Platform Services**
- **Apache2**: Web server and reverse proxy
- **PostgreSQL**: Database clusters (versions 9.6 and 14)
- **Redis HA**: High availability Redis instances
- **Mosquitto**: MQTT message broker
- **Tile38**: Geospatial database (10.128.0.11:9851)

#### **Microservices**
- **Count**: 260+ Node.js services managed by PM2
- **Management**: PM2 process manager with ecosystem configuration
- **Logs**: Accessible via `pm2m logs <service-name>` with time filtering
- **Monitoring**: Health checks and status monitoring via PM2

### **Investigation Commands and Tools**

#### **System Health Commands**
```bash
# OS Health Check
uptime && free -h && df -h / && iostat 1 1

# Platform Services Status
systemctl status apache2 postgresql redis mosquitto tile38 --no-pager

# Redis BDS Connection Test
redis-cli -h 10.128.0.21 -p 6379 ping
```

#### **Microservice Investigation**
```bash
# PM2 Service Status
pm2 list | grep <service-name>
pm2 show <pm2-id>

# Log Analysis with Time Filtering
../../pm2/scripts/pm2m logs <service-name> --from now-12h --to now
../../pm2/scripts/pm2m logs <service-name> --from now-1d --to now | grep -E "error|Error|failed|Failed"
```

#### **Workflow Analysis Commands**
```bash
# Find Workflow ID from Logs
../../pm2/scripts/pm2m logs work-admin-dev --from now-12h --to now | grep -E "workflow.*created|LOG.*registerUserByAdmin"

# Retrieve Complete Workflow (Source + Runtime)
redis-cli -h 10.128.0.21 -p 6379 JSON.GET "beamdevlive:workflow:<workflowId>:work-admin"

# Filter Workflow State Transitions
../../pm2/scripts/pm2m logs work-admin-dev --from now-12h --to now | grep "LOG.*registerUserByAdmin" | head -20
```

#### **MQTT Testing Commands**
```bash
# Generate UUID for Request
REQUEST_ID=$(uuidgen)

# Subscribe to Reply Topic
mosquitto_sub -h localhost -p 1883 -u explorer -P beamL1ve -t "beamdevlive/service/work-admin/service/<org-service>/register/reply" -C 1 &

# Publish Request
mosquitto_pub -h localhost -p 1883 -u explorer -P beamL1ve -t "beamdevlive/service/work-admin/service/<org-service>/register" -m '{"id":"'$REQUEST_ID'","pattern":"beamdevlive/service/work-admin/service/<org-service>/register","data":{...}}'
```

### **Platform-Specific Investigation Lessons**

#### **Admin Registration Troubleshooting (beamdevlive ecosystem)**
- **force1FR Flag Check**: Always verify `force1FR: true` for admin-initiated registrations
- **TypeId 2 Issues**: 2FA registrations require proper force1FR handling
- **Common Error Pattern**: `"user with ids cannot be created"` often indicates force1FR: false issue
- **Security Working**: Services rejecting unverified 2FA are functioning correctly
- **Investigation Priority**: Check authentication parameters before assuming service bugs

## Workspace Commands

### Root Level Commands:
```bash
# Install all workspace dependencies
npm run install:all

# Run commands across all workspaces
npm run build --workspaces
npm run test --workspaces
npm run lint --workspaces

# Clean all workspaces
npm run clean --workspaces

# Rules protection
npm run protect-rules <target>     # Protect rules (root, staging, all)
npm run unprotect-rules <target>   # Unprotect rules
npm run rules-status               # Show protection status
```

### Platform-Specific Work:
```bash
# Set context and navigate to specific platform (RECOMMENDED)
source scripts/set-context.sh staging

# Or load aliases first, then use short commands
source scripts/context-aliases.sh
set-context staging

# Return to monorepo root
set-context
```

## Context Switching System

### Quick Start:
```bash
# Load context aliases (optional, for convenience)
source scripts/context-aliases.sh

# Set context (switches config + changes directory + npm install)
set-context staging

# Work in platform-specific environment with session management
npm run open-session "performance-optimization"

# Work with platform-specific .cursorrules and MCP settings...
# Document work in session-notes.md...

# Close session and generate documentation
npm run close-session

# Return to monorepo root
set-context
```

### Available Commands:
- **`source scripts/set-context.sh <platform>`**: Set context and cd to platform
- **`source scripts/set-context.sh <platform> --skip-install`**: Set context without npm install
- **`source scripts/set-context.sh`**: Restore monorepo root configuration
- **`npm run context-status`**: Check current active context
- **`source scripts/context-aliases.sh`**: Load convenient aliases

### How It Works:
1. **Initialize**: Always restores root configs first (removes any existing symlinks)
2. **Backup**: Original monorepo configs are backed up (only once)
3. **Symlink**: Platform-specific configs are symlinked to root
4. **Directory**: Working directory changes to platform folder
5. **Install**: npm install runs in platform workspace (unless --skip-install)
6. **Restore**: Unset restores original configs and returns to root


## Development Workflow

### Working with Platforms:
1. **Set Context**: Use `source scripts/set-context.sh <platform>` to activate platform-specific configuration and navigate to workspace
2. **Open Session**: Use `npm run open-session <session-name>` for all support work
3. **Platform-Specific Work**: Use platform and session-specific MCP settings and rules automatically
4. **Document Work**: All actions documented in session notes and auto-generated summaries
5. **Close Session**: Use `npm run close-session` to generate comprehensive documentation
6. **Return to Root**: Use `source scripts/set-context.sh` (no args) to restore monorepo configuration
7. **Commit Changes**: Always commit from the root level to maintain monorepo integrity

### Git Workflow:
```bash
# Always commit from root level
cd ~/support-staging
git add .
git commit -m "feat(platform): description of changes"
git push origin main
```

## Best Practices

1. **Platform Isolation**: Each platform workspace is self-contained
2. **Context Switching**: Always use context system for platform-specific work
3. **Session Management**: Use session system for all support work
4. **Rules Protection**: Protect rules when not actively modifying them
5. **Shared Dependencies**: Common dependencies managed at root level
6. **Documentation**: Platform-specific docs stay in platform workspace
7. **MCP Settings**: Platform-specific Redis/service connections in platform MCP settings
8. **Support Sessions**: Always use session management system for structured documentation

## Troubleshooting

### Workspace Issues:
```bash
# Reinstall all workspace dependencies
npm run clean --workspaces
npm run install:all

# Check workspace configuration
npm ls --workspaces

# Verify platform structure
ls -la platforms/*/
```

### Context Switching Issues:
```bash
# Check current context
npm run context-status

# Reset to root configuration
source scripts/set-context.sh

# Check rules protection status
npm run rules-status
```

### Session Management Issues:
```bash
# Check active session (in platform workspace)
npm run session-status

# List all sessions
npm run list-sessions

# Force close session if needed
rm .active-session
```

## Security and Safety

- **Rules Protection**: Prevents accidental modification of critical .cursorrules files
- **Context Isolation**: Platform configurations don't interfere with each other
- **Session Isolation**: Each support session has its own rules and documentation context
- **Backup System**: Original configurations are always preserved and restorable
- **Structured Documentation**: All support work is automatically documented with timestamps and metadata

## Firebase FCM Token Management

### **Firebase Configuration and Credentials**

#### **Environment Configuration (beamdevlive ecosystem)**
- **Project ID**: `beam-live-passenger`
- **Client Email**: `firebase-adminsdk-fffpq@beam-live-passenger.iam.gserviceaccount.com`
- **Private Key Source**: `/var/www/beamdevlive/notification-service/.env`
- **Database URL**: `https://beamlive-ff2d7.firebaseio.com`

#### **FCM Token Storage in BDS**
- **Correct Index**: `beamdevlive:device:token`
- **Search Tag**: `@fcmTokenUserId:{userId}`
- **Token Path**: `$.nonpersistent.static.live.fcmToken.token`
- **Wrong Index**: `beamdevlive:deviceUdidIndex` (commonly misused by services)

#### **Firebase Credentials Extraction Script**
```bash
# Extract and format Firebase private key from notification-service
cat > extract_firebase_key.sh << 'EOF'
#!/bin/bash
echo "=== Extracting Firebase Private Key ==="
key_line=$(grep "FIREBASE_ADMIN_SERVICE_ACCOUNT_PRIVATE_KEY" /var/www/beamdevlive/notification-service/.env)
private_key_raw=$(echo "$key_line" | cut -d'=' -f2-)
echo "$private_key_raw" | \
  sed 's/-----BEGINPRIVATEKEY-----/-----BEGIN PRIVATE KEY-----/g' | \
  sed 's/-----ENDPRIVATEKEY-----/-----END PRIVATE KEY-----/g' | \
  sed 's/\\n/\n/g' > formatted_key.txt
echo "✅ Key saved to: formatted_key.txt"
EOF
chmod +x extract_firebase_key.sh
```

### **FCM Token Testing and Validation Tools**

#### **Complete Token Validation Script Template**
```javascript
const admin = require('firebase-admin');
const fs = require('fs');

async function validateFCMTokens() {
  try {
    // Load properly formatted Firebase credentials
    const privateKey = fs.readFileSync('formatted_key.txt', 'utf8');
    const firebaseConfig = {
      projectId: "beam-live-passenger",
      clientEmail: "firebase-adminsdk-fffpq@beam-live-passenger.iam.gserviceaccount.com",
      privateKey: privateKey
    };

    // Initialize Firebase Admin SDK
    if (admin.apps.length > 0) {
      await Promise.all(admin.apps.map(app => app.delete()));
    }
    admin.initializeApp({
      credential: admin.credential.cert(firebaseConfig)
    });

    // Load FCM tokens from BDS or file
    const tokens = [/* token array */];
    
    // Batch validation with error handling
    const batchSize = 10;
    let validTokens = 0;
    let invalidTokens = 0;
    const errorBreakdown = {};
    
    for (let i = 0; i < tokens.length; i += batchSize) {
      const batch = tokens.slice(i, i + batchSize);
      
      for (const token of batch) {
        try {
          await admin.messaging().send({
            token: token,
            notification: { title: 'Test', body: 'Validation' },
            data: { test: 'validation' }
          }, true); // dryRun = true
          
          validTokens++;
        } catch (error) {
          invalidTokens++;
          const errorCode = error.code || 'unknown';
          errorBreakdown[errorCode] = (errorBreakdown[errorCode] || 0) + 1;
        }
      }
    }
    
    // Save results
    const results = {
      validation_timestamp: new Date().toISOString(),
      total_tokens: tokens.length,
      valid_tokens: validTokens,
      invalid_tokens: invalidTokens,
      validation_rate: ((validTokens/tokens.length)*100).toFixed(1) + '%',
      error_breakdown: errorBreakdown
    };
    
    fs.writeFileSync('fcm-validation-results.json', JSON.stringify(results, null, 2));
    console.log(`✅ Validation complete: ${validTokens}/${tokens.length} valid (${results.validation_rate})`);
    
  } catch (error) {
    console.error('❌ Validation failed:', error.message);
  }
}

validateFCMTokens();
```

#### **FCM Token Collection from BDS Script Template**
```bash
# Collect FCM tokens for specific users from correct BDS index
collect_user_fcm_tokens() {
  local user_ids=("$@")
  
  echo "{"
  echo "  \"collection_timestamp\": \"$(date -Iseconds)\","
  echo "  \"user_tokens\": ["
  
  local first=true
  for userId in "${user_ids[@]}"; do
    if [ "$first" = false ]; then echo ","; fi
    first=false
    
    echo -n "    {\"user_id\": \"$userId\", \"fcm_tokens\": ["
    
    # Query correct BDS index for FCM tokens
    device_objects=$(redis-cli -h localhost -p 6379 FT.SEARCH "beamdevlive:device:token" "@fcmTokenUserId:{$userId}" LIMIT 0 100 2>/dev/null | grep "beamdevlive:device:")
    
    local token_first=true
    if [ -n "$device_objects" ]; then
      while IFS= read -r device_key; do
        if [ -n "$device_key" ]; then
          token=$(redis-cli -h localhost -p 6379 JSON.GET "$device_key" "$.nonpersistent.static.live.fcmToken.token" 2>/dev/null)
          clean_token=$(echo "$token" | sed 's/^\[\"\(.*\)\"\]$/\1/' | sed 's/^"\(.*\)"$/\1/')
          
          if [ -n "$clean_token" ] && [ "$clean_token" != "null" ] && [ "$clean_token" != "[]" ]; then
            if [ "$token_first" = false ]; then echo -n ", "; fi
            token_first=false
            echo -n "\"$clean_token\""
          fi
        fi
      done <<< "$device_objects"
    fi
    
    echo -n "]}"
  done
  
  echo ""
  echo "  ]"
  echo "}"
}

# Usage: collect_user_fcm_tokens "102563" "111557" "9"
```

#### **Firebase Authentication Debug Script Template**
```javascript
// Debug Firebase configuration and test authentication
async function debugFirebaseAuth() {
  try {
    // Extract Firebase config from notification-service .env
    const envContent = fs.readFileSync('/var/www/beamdevlive/notification-service/.env', 'utf8');
    
    const projectIdMatch = envContent.match(/FIREBASE_ADMIN_SERVICE_ACCOUNT_PROJECT_ID=(.+)/);
    const clientEmailMatch = envContent.match(/FIREBASE_ADMIN_SERVICE_ACCOUNT_CLIENT_EMAIL=(.+)/);
    
    const projectId = projectIdMatch ? projectIdMatch[1].trim() : 'beam-live-passenger';
    const clientEmail = clientEmailMatch ? clientEmailMatch[1].trim() : 'firebase-adminsdk-fffpq@beam-live-passenger.iam.gserviceaccount.com';
    
    console.log('Firebase Config:');
    console.log('Project ID:', projectId);
    console.log('Client Email:', clientEmail);
    
    // Test authentication with extracted config
    const privateKey = fs.readFileSync('formatted_key.txt', 'utf8');
    const config = { projectId, clientEmail, privateKey };
    
    admin.initializeApp({ credential: admin.credential.cert(config) });
    console.log('✅ Firebase authentication successful');
    
    // Test messaging service
    const messaging = admin.messaging();
    console.log('✅ Messaging service accessible');
    
  } catch (error) {
    console.error('❌ Authentication failed:', error.message);
  }
}
```

### **FCM Token Management Best Practices**

#### **Token Validation Workflow**
1. **Extract Credentials**: Use `extract_firebase_key.sh` to get properly formatted private key
2. **Collect Tokens**: Query `beamdevlive:device:token` index with `@fcmTokenUserId` tag
3. **Validate Tokens**: Use Firebase Admin SDK with dry run to test token validity
4. **Error Analysis**: Categorize errors (`registration-token-not-registered`, `invalid-registration-token`)
5. **Cleanup**: Remove invalid tokens from BDS to improve performance

#### **Common FCM Token Issues**
- **Wrong Index**: Services querying `beamdevlive:deviceUdidIndex` instead of `beamdevlive:device:token`
- **Invalid Tokens**: 70%+ of stored tokens may be unregistered with FCM
- **Missing Tokens**: Only ~35% of users typically have FCM tokens available
- **Authentication**: Wrong Firebase project configuration (beam-dev-live vs beam-live-passenger)

#### **Performance Optimization**
- **Token Caching**: Cache valid tokens to reduce Firebase API calls
- **Batch Validation**: Process tokens in batches of 10-100 to avoid rate limits
- **Regular Cleanup**: Remove invalid tokens weekly to reduce BDS storage
- **Monitoring**: Track token validity rates and delivery success metrics

## Project Context

This monorepo supports multiple staging environments with platform-specific infrastructure, services, and troubleshooting procedures. Each platform workspace contains complete documentation and tools for that specific environment.

The system enforces structured workflows through context switching, session management, and rules protection to ensure consistent documentation and prevent accidental modifications to critical configuration files.
