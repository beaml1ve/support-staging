# Support Staging Monorepo Rules

## Monorepo Structure

This is an npm workspace-based monorepo for support staging environments. Each platform has its own workspace with specific configurations and tools.

## Core Constraints and Principles


### 0. **CRITICAL: Sparse Checkout Enforcement Rule**
- **MANDATORY**: Only one platform allowed in checkout at any time
- **REQUIREMENT**: Must use sparse checkout with exactly one platform
- **Enforcement**: All npm operations validate sparse checkout configuration
- **Validation**: Automatic validation on `npm install` and `preinstall` hooks
- **Commands Allowed in Root**:
  - `scripts/setup-sparse-checkout.sh <platform>` - Setup sparse checkout
  - `npm run validate-checkout` - Validate current checkout
  - `npm run get-platform` - Get active platform name
  - `npm run rules-status` - Check rules protection status
  - `npm run protect-rules <target>` - Protect rules
  - `npm run unprotect-rules <target>` - Unprotect rules
  - Git operations (`git add`, `git commit`, `git push`)
- **REJECTED Operations in Root**:
  - Multiple platforms checked out simultaneously
  - Working without sparse checkout enabled
  - Any platform-specific work in root context
- **Error Message**: "❌ SPARSE CHECKOUT REQUIRED: Use 'scripts/setup-sparse-checkout.sh <platform>' to configure single platform checkout"

### 1. **Rules Protection System**
- **CRITICAL**: Root and platform .cursorrules files are protected by default
- **Modification Requires**: Explicit unprotection via `npm run unprotect-rules <target>`
- **Protection Commands**:
  - `npm run protect-rules root` - Protect root rules
  - `npm run protect-rules staging` - Protect platform rules
  - `npm run unprotect-rules root` - Allow root rules modification
  - `npm run unprotect-rules staging` - Allow platform rules modification
  - `npm run rules-status` - Show protection status
- **Auto-Protection**: Rules should be re-protected after modifications

### 2. **Sparse Checkout System**
- **MANDATORY**: Use sparse checkout for platform isolation
- **Commands**:
  - `scripts/setup-sparse-checkout.sh <platform>` - Setup sparse checkout for platform
  - `scripts/setup-sparse-checkout.sh status` - Show current sparse checkout status
  - `npm run validate-checkout` - Validate sparse checkout configuration
  - `npm run get-platform` - Get currently active platform name
- **Behavior**: Sparse checkout ensures only one platform is present in the working directory
- **Benefits**: No context switching needed, cleaner workspace, automatic platform isolation

### 3. **Session Management System**
- **MANDATORY**: When opening a new chat, MUST ask about the tasks the chat is opened for
- **REQUIRED**: Using the information received, a new session MUST be opened using the open-session utility
- **REQUIRED**: Use session management for all support work
- **Session Commands** (in platform workspace):
  - `npm run open-session <session-name>` - Create dedicated session folder
  - `npm run close-session` - Close session and generate documentation
  - `npm run session-status` - Check active session
  - `npm run list-sessions` - List all sessions
- **Centralized Utilities**: Session management scripts located in `session/`
- **PM2 Management**: PM2 restart and state management utilities located in `pm2-restart/`
- **Session Structure**: Each session gets isolated folder with own .cursorrules, notes, and documentation
- **Documentation**: Auto-generated session summaries and chat history for continuation

#### Session Workflow:
1. **Open Session**: `npm run open-session <session-name>` (in platform workspace)
2. **Work in Session**: Use session-specific rules and document in session-notes.md
3. **Close Session**: `npm run close-session` - generates comprehensive documentation

#### Session Documentation Structure:
```
session-logs/YYYY-MM-DD_HH-MM-SS_session-name/
├── .cursorrules           # Session-specific rules (editable)
├── session-notes.md       # Manual notes and observations
├── chat-history.md        # Chat history for continuation
├── session-summary.md     # Auto-generated comprehensive summary
└── session-metadata.json # Session tracking data
```

#### Session Best Practices:
- **MANDATORY**: Start every new chat by asking about the tasks and opening a session
- **Always use sessions** for all support work and troubleshooting
- **Document everything** in session-notes.md during the session
- **Session-specific rules** can be modified in the session's .cursorrules file
- **Auto-generated summaries** provide complete documentation on session close
- **Chat history** enables session continuation across multiple conversations
- **Session isolation** ensures each support case has dedicated context and rules

### 4. **Microservice Management**
- **CRITICAL**: Ecosystem microservices can be managed using Docker or PM2
- **Platform Flexibility**: Each platform may use different orchestration approaches
- **Service Discovery**: Services must be discoverable regardless of management system
- **State Management**: Both Docker and PM2 services require proper state management
- **Monitoring**: Health checks and monitoring apply to both orchestration types
- **Log File Access**: When microservices are running in PM2 mode, the location of the logs can be retrieved from the PM2 daemon using `service.pm2_env.pm_out_log_path` and `service.pm2_env.pm_err_log_path`. The log rotation compresses log files with `.gz` extension.
- **Log Processing**: When microservices are under PM2 management, use `pm2m logs <service-name>` command with time filters to process microservice logs. This command merges compressed and uncompressed log files chronologically, prefixes entries with log type ([OUT]/[ERR]), and supports Grafana-style time expressions (e.g., `pm2m logs service-name --from now-2d --to now`).

### 5. **Workflow Analysis and MQTT Communication Rules**

#### **Redis Workflow BDS Analysis**
- **Workflow BDS**: Running workflow instances stored with pattern `beamdevlive:workflow:objectId:serviceId`
- **Complete Source**: Workflow BDS objects contain both runtime data AND complete workflow source code
- **Key Retrieval**: Use `JSON.GET` for Redis JSON documents, not standard `GET`
- **Efficient Analysis**: No need to check config BDS separately - workflow BDS has everything needed

#### **Workflow Step Analysis**
- **Declarative Structure**: Workflows are JSON configurations with `transitions`, `dataset`, and `sensors`
- **State Flow**: Each transition has `condition`, `updates`, `execute`, `publish`, `log`, and `catch` sections
- **Dataset Context**: Contains `input`, `local`, and `output` sections for workflow variables
- **Dynamic Evaluation**: Use JavaScript `eval` expressions for runtime payload generation
- **State Tracking**: Monitor workflow progression through status changes in `dataset.output.status`

#### **Workflow Step Evaluation**
- **Payload Generation**: Use `payload.eval` expressions to dynamically create MQTT payloads
- **URI Construction**: Dynamic URI generation using template literals with dataset variables
- **Context Variables**: Access workflow data through `dataset.local`, `dataset.input`, `dataset.output`
- **Error Handling**: `catch` blocks automatically transition to error states (e.g., `79-error`)
- **Log Messages**: Dynamic log generation using `message.eval` expressions

#### **MQTT Message Publishing and Subscribing Rules**

##### **Topic Structure**
- **Pattern**: `ecosystem/sourceType/sourceId/destinationType/destinationId/topicBody`
- **Example**: `beamdevlive/service/work-admin/service/org-saferide-africa/register`
- **Reply Topics**: Append `/reply` to the original topic for responses

##### **Message Formats**

**Broadcast Format** (No reply expected):
```json
{
  "userIds": [...],
  "deviceIds": [...],
  "authTypeParams": [...]
}
```

**Request Format** (Reply expected):
```json
{
  "id": "uuid-v4-generated",
  "pattern": "full/topic/path",
  "data": {
    "userIds": [...],
    "deviceIds": [...],
    "authTypeParams": [...]
  }
}
```

##### **MQTT Commands**
- **Subscribe**: `mosquitto_sub -h host -p port -u user -P password -t "topic" -v`
- **Publish**: `mosquitto_pub -h host -p port -u user -P password -t "topic" -m "payload"`
- **Subscribe Options**: 
  - `-C 1`: Exit after receiving 1 message
  - `-W seconds`: Wait timeout
  - `-v`: Verbose (show topic with message)
- **UUID Generation**: Use `uuidgen` for request IDs

##### **Reply Handling**
- **Correlation**: Replies contain the same `id` as the request
- **Error Format**: `{"err": {"data": {...}, "status": false, "message": "..."}, "isDisposed": true, "id": "..."}`
- **Success Format**: `{"response": [...], "status": true, "id": "..."}`

### 6. **Troubleshooting Protocol and Investigation Methodology**

#### **Systematic Troubleshooting Protocol**
- **MANDATORY**: When a new issue appears, follow this order:
  1. **OS Health Check**: System resources, uptime, disk space, memory usage
  2. **Platform Services Health**: Redis, PostgreSQL, Apache2, Mosquitto, Tile38
  3. **Microservices Health**: PM2 status, service-specific health checks
  4. **Service Chain Analysis**: Trace errors through complete communication chain

#### **Error Investigation Chain**
- **Log Correlation**: Use time-based filtering to correlate errors across multiple services
- **Service Dependencies**: Understand complete request flow (API → Workflow → MQTT → Target Service)
- **Don't Stop at Symptoms**: Trace errors to their actual source, not just where they're reported
- **Validate with Testing**: Use live MQTT testing to confirm findings

#### **Error Filtering and Prioritization**
- **IGNORE SchemaService Errors**: SchemaService errors (schema validation, missing schema files, 404 errors) are NOT important and should be filtered out during investigation
- **Focus on Business Logic**: Prioritize connection issues, workflow failures, and service communication problems
- **Skip Schema Validation Issues**: Do not investigate or report schema-related problems as they are considered low priority

#### **Workflow Investigation Best Practices**
- **Efficient Analysis**: Use workflow BDS directly - contains both source code and runtime data
- **State Progression**: Track workflow through actual state transitions using LOG entries
- **Dataset Analysis**: Examine input, local, and output datasets for complete context
- **Error Correlation**: Match workflow errors with target service logs using timestamps

#### **MQTT Communication Testing**
- **Live Validation**: Always test actual MQTT communication to validate log analysis
- **Proper Format**: Use request format with UUID correlation for replies
- **Topic Structure**: Follow `ecosystem/sourceType/sourceId/destinationType/destinationId/topicBody` pattern
- **Authentication**: Use proper credentials for MQTT broker access

#### **Key Investigation Lessons Learned**

##### **Admin Registration and force1FR Flag (Session: 2025-09-08)**
- **Critical Learning**: When investigating admin-initiated user registration failures, check the `force1FR` flag
- **TypeId 2 Authentication**: 2-Factor Authentication requires email/phone verification via OTP
- **Admin Limitation**: Admins have no access to user's email/phone for verification channels
- **force1FR Purpose**: Must be `true` for admin registrations to bypass verification requirements
- **Common Mistake**: Workflow invoked with `force1FR: false` causes legitimate security rejection
- **Investigation Trap**: Don't assume service logic bug - verify authentication parameters first
- **Security Validation**: Services correctly enforcing 2FA requirements are working properly

### 7. **BDS (Beam Data Store) Object Structure and Tagging**

#### **BDS Object Structure**
- **Partition Array**: All BDS objects contain a `partition` array that contains tags
- **Tag Format**: Tags are strings in the format "type:value" (e.g., "service:cudb", "status:active", "org:beamdevlive")
- **Organization Membership**: Objects belonging to an organization get tagged with "org:<serviceId>" (e.g., "org:cudb-root", "org:cudb-client")

#### **BDS Index Structure**
- **partitionSegments**: Separates tags using ":" separator to create an array (of arrays), then flattens the result
  - Enables selection by type and value separately
  - Example: Tag "org:cudb-root" becomes ["org", "cudb-root"] in partitionSegments
  - Allows queries like: `@type:{org}` or `@value:{cudb-root}`
- **partitions**: Contains the full tag string and is a TAG type index segment
  - Preserves complete tag strings for exact matching
  - Example: Tag "org:cudb-root" remains "org:cudb-root" in partitions
  - Allows queries like: `@partitions:{"org\\:cudb-root"}`

#### **BDS Query Patterns**
- **Organization Object Selection**: To select objects tagged to an organization, use: `@partitions:{"org:<serviceId>"}` (properly escaped)
- **Special Character Escaping**: Colons and other special characters must be escaped with backslashes in queries
- **Efficient Querying**: Uses the partitions TAG type index segment for fast exact tag matching

#### **Page Object Types**
- **Page BDS objects** have `persistent.static.metadata.type` property with valid types:
  1. "ai" - AI-related pages
  2. "assist" - Assistant pages  
  3. "broadcast" - Broadcast pages
  4. "event" - Event pages
  5. "friend" - Friend-related pages
  6. "iot" - IoT (Internet of Things) pages
  7. "regular" - Regular pages

### 8. **Workspace Isolation**
- **Platform Independence**: Each platform workspace is completely self-contained
- **Configuration Isolation**: Platform-specific .cursorrules and MCP settings
- **Dependency Management**: Platform-specific package.json and dependencies
- **Session Isolation**: Each session within a platform has its own rules and context

## Workspace Organization
```
support-staging/                 # Root monorepo
├── package.json                # Root package.json with workspaces config
├── .cursor/                    # Root MCP settings
│   └── mcp_settings.json      # Monorepo-wide MCP configuration
├── .cursorrules               # This file - monorepo rules
├── scripts/                   # Monorepo management scripts
│   ├── set-context.sh         # Context switching (with directory change)
│   ├── unset-context.sh       # Legacy unset script
│   ├── context-aliases.sh     # Convenient aliases
│   └── protect-rules.js       # Rules protection system
├── session/                   # Session management scripts
│   └── scripts/
│       ├── open-session.js    # Create new support sessions
│       ├── close-session.js   # Close sessions with Slack integration
│       ├── session-status.js  # Check session status
│       └── list-sessions.js   # List all sessions
├── slack-webhook/             # Slack integration workspace
│   ├── package.json           # Slack workspace package.json
│   ├── scripts/
│   │   └── slack-notifier.js  # Slack notification module
│   ├── slack-config.json      # Slack webhook configuration
│   ├── SLACK_SETUP.md         # Setup documentation
│   └── README.md              # Workspace documentation
└── platforms/                 # Platform-specific workspaces
    └── staging/               # Staging platform workspace
        ├── package.json       # Workspace-specific package.json
        ├── .cursor/           # Platform-specific MCP settings
        │   └── mcp_settings.json
        ├── .cursorrules       # Platform-specific rules
        ├── session-logs/      # Support session documentation
```

## Available Platforms
- **platforms/staging**: Staging environment workspace
  - Platform-specific configuration in platform .cursorrules
  - Platform services and connection details in platform workspace
  - Microservices managed per platform configuration

## Slack Integration
- **Dedicated workspace**: `slack-webhook` workspace for cross-platform notifications
- **Configuration**: Set `SLACK_WEBHOOK_URL` environment variable or create `slack-webhook/slack-config.json`
- **Auto-notifications**: Session summaries automatically sent to Slack when sessions close
- **Manual notifications**: Use `npm run slack-notify <session-folder>` or `npm run slack-test`
- **Validation**: Use `npm run slack-validate` to check configuration
- **Documentation**: See `slack-webhook/SLACK_SETUP.md` for complete setup instructions

## Workspace Commands

### Root Level Commands:
```bash
# Install all workspace dependencies
npm run install:all

# Run commands across all workspaces
npm run build --workspaces
npm run test --workspaces
npm run lint --workspaces

# Clean all workspaces
npm run clean --workspaces

# Rules protection
npm run protect-rules <target>     # Protect rules (root, staging, all)
npm run unprotect-rules <target>   # Unprotect rules
npm run rules-status               # Show protection status

# Slack integration (slack-webhook workspace)
npm run slack-test                 # Test Slack integration with latest session
npm run slack-notify <session>     # Send specific session to Slack
npm run slack-validate             # Validate Slack webhook configuration
npm run slack-setup                # Show Slack setup instructions
```

### Platform-Specific Work:
```bash
# Set context and navigate to specific platform (RECOMMENDED)
source scripts/set-context.sh staging

# Or load aliases first, then use short commands
source scripts/context-aliases.sh
set-context staging

# Return to monorepo root
set-context
```

## Context Switching System

### Quick Start:
```bash
# Load context aliases (optional, for convenience)
source scripts/context-aliases.sh

# Set context (switches config + changes directory + npm install)
set-context staging

# Work in platform-specific environment with session management
npm run open-session "performance-optimization"

# Work with platform-specific .cursorrules and MCP settings...
# Document work in session-notes.md...

# Close session and generate documentation
npm run close-session

# Return to monorepo root
set-context
```

### Available Commands:
- **`source scripts/set-context.sh <platform>`**: Set context and cd to platform
- **`source scripts/set-context.sh <platform> --skip-install`**: Set context without npm install
- **`source scripts/set-context.sh`**: Restore monorepo root configuration
- **`npm run context-status`**: Check current active context
- **`source scripts/context-aliases.sh`**: Load convenient aliases

### How It Works:
1. **Initialize**: Always restores root configs first (removes any existing symlinks)
2. **Backup**: Original monorepo configs are backed up (only once)
3. **Symlink**: Platform-specific configs are symlinked to root
4. **Directory**: Working directory changes to platform folder
5. **Install**: npm install runs in platform workspace (unless --skip-install)
6. **Restore**: Unset restores original configs and returns to root


## Development Workflow


**⚠️ CRITICAL: All platform work must be done with sparse checkout. Only one platform allowed in checkout.**

### Working with Platforms:
1. **Setup Sparse Checkout**: Use `scripts/setup-sparse-checkout.sh <platform>` to configure single platform checkout
2. **Validate Setup**: Run `npm install` (automatically validates sparse checkout)
3. **Navigate to Platform**: `cd platforms/<platform>/` to work in platform context
4. **Open Session**: Use `npm run open-session <session-name>` for all support work
5. **Platform-Specific Work**: Use platform and session-specific MCP settings and rules automatically
6. **Document Work**: All actions documented in session notes and auto-generated summaries
7. **Close Session**: Use `npm run close-session` to generate comprehensive documentation
8. **Commit Changes**: Always commit from the root level to maintain monorepo integrity

### Git Workflow:
```bash
# Always commit from root level
cd ~/support-staging
git add .
git commit -m "feat(platform): description of changes"
git push origin main
```

## Best Practices

0. **Sparse Checkout Enforcement**: Always use sparse checkout with exactly one platform - never work with multiple platforms checked out

1. **Platform Isolation**: Each platform workspace is completely isolated via sparse checkout
2. **Sparse Checkout Setup**: Always use `scripts/setup-sparse-checkout.sh <platform>` for platform selection
3. **Session Management**: Use session system for all support work within the platform
4. **Rules Protection**: Protect rules when not actively modifying them
5. **Validation**: Run `npm install` to automatically validate sparse checkout configuration
6. **Documentation**: Platform-specific docs stay in platform workspace
7. **MCP Settings**: Platform-specific Redis/service connections in platform MCP settings
8. **Support Sessions**: Always use session management system for structured documentation

## Troubleshooting

### Workspace Issues:
```bash
# Reinstall all workspace dependencies
npm run clean --workspaces
npm run install:all

# Check workspace configuration
npm ls --workspaces

# Verify platform structure
ls -la platforms/*/
```

### Context Switching Issues:
```bash
# Check current context
npm run context-status

# Reset to root configuration
source scripts/set-context.sh

# Check rules protection status
npm run rules-status
```

### Session Management Issues:
```bash
# Check active session (in platform workspace)
npm run session-status

# List all sessions
npm run list-sessions

# Force close session if needed
rm .active-session
```

## Security and Safety

- **Rules Protection**: Prevents accidental modification of critical .cursorrules files
- **Context Isolation**: Platform configurations don't interfere with each other
- **Session Isolation**: Each support session has its own rules and documentation context
- **Backup System**: Original configurations are always preserved and restorable
- **Structured Documentation**: All support work is automatically documented with timestamps and metadata

## Project Context

This monorepo supports multiple staging environments with platform-specific infrastructure, services, and troubleshooting procedures. Each platform workspace contains complete documentation and tools for that specific environment.

The system enforces structured workflows through context switching, session management, and rules protection to ensure consistent documentation and prevent accidental modifications to critical configuration files.
